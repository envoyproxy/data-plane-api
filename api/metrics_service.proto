syntax = "proto3";

// [#proto-status: draft]

package envoy.api.v2;

import "api/base.proto";
import "api/grpc_cluster.proto";

import "metrics.proto";

import "validate/validate.proto";

// Service for streaming metrics to server that consumes the metrics data. It uses Prometheus metric
// data model as a standard to represent metrics information.
service MetricsService {
  // Envoy will connect and send StreamMetricsMessage messages forever. It does not expect any
  // response to be sent as nothing would be done in the case of failure.
  rpc StreamMetrics(stream StreamMetricsMessage) returns (StreamMetricsResponse) {
  }
}

message StreamMetricsResponse {
}

message StreamMetricsMessage {
  message Identifier {
    // The node sending metrics over the stream.
    Node node = 1 [(validate.rules).message.required = true];
  }

  // Identifier data effectively is a structured metadata.
  // As a performance optimization this will only be sent in the first message on the stream.
  Identifier identifier = 1;

  // A list of metric entries
  repeated io.prometheus.client.MetricFamily envoy_metrics = 2;
}

// Configuration structure for Metrics Service. It is a :ref: 'StatsSink <envoy_api_msg_StatsSink>'
// opaque configuration that will be used to create a StatsSink.
message MetricsServiceConfig {
  // The upstream Grpc cluster that hosts the metrics service.
  GrpcCluster cluster = 1 [(validate.rules).message.required = true];
}
