syntax = "proto3";

// [#proto-status: draft]

// [#protodoc-title: Metrics Service]

package envoy.api.v2;

import "api/base.proto";
import "api/grpc_service.proto";

import "metrics.proto";

import "validate/validate.proto";

// Service for streaming metrics to server that consumes the metrics data. It uses Prometheus metric
// data model as a standard to represent metrics information.
service MetricsService {
  // Envoy will connect and send StreamMetricsMessage messages forever. It does not expect any
  // response to be sent as nothing would be done in the case of failure.
  rpc StreamMetrics(stream StreamMetricsMessage) returns (StreamMetricsResponse) {
  }
}

message StreamMetricsResponse {
}

message StreamMetricsMessage {
  message Identifier {
    // The node sending metrics over the stream.
    Node node = 1 [(validate.rules).message.required = true];
  }

  // Identifier data effectively is a structured metadata.As a performance optimization this will 
  // only be sent in the first message on the stream.
  Identifier identifier = 1;

  // A list of metric entries
  repeated io.prometheus.client.MetricFamily envoy_metrics = 2;
}

// Metrics Service is configured as a built-in *envoy.metrics_service* :ref:`StatsSink
// <envoy_api_msg_StatsSink>`. This opaque configuration will be used to create Metrics Service.
message MetricsServiceConfig {
  // The upstream gRPC cluster that hosts the metrics service.
  GrpcService grpc_service = 1 [(validate.rules).message.required = true];
}
