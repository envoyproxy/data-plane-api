syntax = "proto3";

// [#proto-status: draft]

package envoy.api.v2;

import "api/base.proto";

import "google/api/annotations.proto";
import "metrics.proto";

// Service for streaming metrics to server that consumes the metrics data. It uses Prometheus metric
// data model as a standard to represent metrics information.
service MetricsService {
  // Envoy will connect and send StreamMetricsMessage messages forever. It does not expect any
  // response to be sent as nothing would be done in the case of failure.
  rpc StreamMetrics(stream StreamMetricsMessage) returns (StreamMetricsResponse) {
  }
}

message StreamMetricsResponse {
}

message StreamMetricsMessage {
  message Identifier {
    // The node sending the access log messages over the stream.
    Node node = 1;
  }

  // Identifier data effectively is a structured metadata.
  // As a performance optimization this will only be sent in the first message on the stream.
  Identifier identifier = 1;

  // A list of metric entries
  repeated io.prometheus.client.MetricFamily envoy_metrics = 2;
}

// Configuration structure.
message MetricsServiceConfig {
  // The name of the upstream cluster that hosts the metrics service. The cluster must be
  // configured in the cluster manager.
  string cluster_name = 1;
}
